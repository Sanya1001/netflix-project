{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd00e993",
   "metadata": {},
   "source": [
    "Name: Keara Hayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70ab8d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e8e268",
   "metadata": {},
   "source": [
    "Using a Netflix database CSV, we can use TFIDF or \"term frequencyâ€“inverse document frequency\" to recommend what to watch next based on what you've just finished. TFIDF looks at the frequency with which words appear to give similarity scores. This code expands and improves [this code](https://colab.research.google.com/drive/1NkUvrLdIQ_QoSl4kfP6XQvWC4xsU-2Ic#sandboxMode=true), which is based on a workshop given by Rounak Banik. The example code is simplistic and does not give sophisticated recommendations. This new and improved code takes ideas and techniques presented there and expands them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5452395",
   "metadata": {},
   "source": [
    "To start, input the name of the movie/show you've just watched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6427540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input a movie or TV show title\n",
    "# this has to be pretty precise to work, as misspellings and capitalization errors will\n",
    "# cause the input to not be understood\n",
    "\n",
    "title = 'Star Trek'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe0196",
   "metadata": {},
   "source": [
    "Next, the database we've been using needs to be loaded in. That database can be found [here](https://www.kaggle.com/datasets/shivamb/netflix-shows). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed82563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the Netflix library\n",
    "netflix = pd.read_csv(\"netflix_titles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049de6b5",
   "metadata": {},
   "source": [
    "Next, the database needs some cleaning. Unimportant columns, like the date it was added to Netflix, the duration of the movie/film, etc are dropped. NaNs are filled with empty strings to prevent errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e570928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out some of the things we care less about\n",
    "netflix_simple = netflix.drop(['date_added', 'release_year', 'duration'], axis = 1)\n",
    "\n",
    "# fill in any NaNs with empty strings so the vectorizing doesn't break\n",
    "netflix_simple.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb513f6",
   "metadata": {},
   "source": [
    "Here we begin pulling our sorting categories. The simplest ones to use with sklearn's TFIDF are the title and description, which are merged together into a single category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d1df10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# things that don't need extra manipulation\n",
    "titledesc = netflix_simple['description'] + netflix_simple['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631f56e5",
   "metadata": {},
   "source": [
    "Sklearn struggles with some of the categories, though. For example, in the case of the cast, actors tend to have multiple names which need to stay together. If they are tokenized separately though, you lose a lot of information. For example, Gates McFadden is an actress in *Star Trek: The Next Generation*, and Bill Gates appears in the documentary *Inside Bill's Brain: Decoding Bill Gates*. If sklearn is allowed to run unaided, watching *TNG* will reccommend the Bill Gates documentary based solely on the fact that *Gates* appears in both of their names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b340b85",
   "metadata": {},
   "source": [
    "To solve this, for both the director column and the cast column, all the whitespace is removed so that actors' names are one \"word,\" which means they are tokenized properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f16b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# things that do need some help, since they contain multiword tokens\n",
    "# what we're doing here is removing all the whitespace so that when we tokenize, there's \n",
    "# no worry about individual words being tokens instead of full names\n",
    "\n",
    "for i in range(len(netflix_simple['cast'])):\n",
    "    netflix_simple['cast'].iloc[i] = netflix_simple['cast'].iloc[i].replace(\" \", \"\")\n",
    "    netflix_simple['director'].iloc[i] = netflix_simple['director'].iloc[i].replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f7ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# like before, assign the colmns to variables so things are cleaner\n",
    "cast = netflix_simple['cast']\n",
    "director = netflix_simple['director']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9666508",
   "metadata": {},
   "source": [
    "Then the columns need to be \"vectorized.\" They have a \"direction\" (the token, for example, the word \"star\") and a magnitude (the frequency with which that word appears)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7143cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tfidf vectorizer:\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
    "\n",
    "# Use vectorizer to create tfidf matrix.\n",
    "tfidf_titledesc = tf.fit_transform(titledesc)\n",
    "tfidf_cast = tf.fit_transform(cast)\n",
    "tfidf_director = tf.fit_transform(director)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6369448e",
   "metadata": {},
   "source": [
    "Based on those vectors, titles are given similarity scores relative to each other. These are matrices that show how similar entries are based on the different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eec78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the similarity matrix so we know how similar the given movie is to the others available\n",
    "sim_titledesc = linear_kernel(tfidf_titledesc, tfidf_titledesc)\n",
    "sim_cast = linear_kernel(tfidf_cast, tfidf_cast)\n",
    "sim_director = linear_kernel(tfidf_director, tfidf_director)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc00ae68",
   "metadata": {},
   "source": [
    "We'll set aside what categories we intend to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c64ea7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the things we'll be using for the ranking\n",
    "metrics = [sim_titledesc, sim_cast, sim_director]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc5215",
   "metadata": {},
   "source": [
    "Here, we reset the index to use the titles of the movies to make searching easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a0ea60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_simple.reset_index(inplace=True)\n",
    "\n",
    "# reindex according to title so that the indexing later is easier\n",
    "indices = pd.Series(netflix_simple.index, index=netflix_simple['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66f1494",
   "metadata": {},
   "source": [
    "And here is the real meat of the recommendations. In short, each category (title + description, cast, and director) is used to create a list of contenders, along with their similarity scores. These similarity scores are added for each recommended entry, and the movie/show that has the high score overall is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2789a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Love of Spock\n"
     ]
    }
   ],
   "source": [
    "# this loop will take all the rating categories and combine them into a final \n",
    "# recommendation list\n",
    "\n",
    "# this is the title you input at the top of the notebook\n",
    "# it is used on the reindexed database to pull the information for that entry\n",
    "index = indices[title]\n",
    "\n",
    "# an empty array to append to in the loop\n",
    "contenders = np.zeros((9,2))\n",
    "\n",
    "for i in metrics:\n",
    "    \n",
    "    # for a given category, find the input movie\n",
    "    row = i[index]\n",
    "    \n",
    "    # pull the similarity scores for that movie\n",
    "    sim_scores = list(enumerate(row))\n",
    "    \n",
    "    # sort the scores, highest score first\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # keep the top 10 entries; entry 0 is excluded because that will nearly always\n",
    "    # be the input title\n",
    "    closest_matches = sim_scores[1:11]\n",
    "    \n",
    "    # get the numerical indices for the movies\n",
    "    movie_indices = [i[0] for i in closest_matches]\n",
    "    \n",
    "    # turn the closest matches into an array\n",
    "    contenders2 = np.array(closest_matches)\n",
    "    \n",
    "    # concatenate to the blank array so we can compile the similarity scores later\n",
    "    contenders = np.concatenate((contenders, contenders2))\n",
    "    \n",
    "# exclude the 0 entries from when we made the \"empty\" array earlier;\n",
    "# keeping them will break the recommendations\n",
    "contenders = contenders[10:,:]   \n",
    "\n",
    "# these are the films/shows; column 1, excluded here, is the similarity scores\n",
    "net = contenders[:,0]\n",
    "\n",
    "finalists = np.zeros((len(contenders), 2))\n",
    "\n",
    "# a loop to skim through the contenders and sum their overall similarity scores\n",
    "for i in range(len(net)):\n",
    "    ind = np.where(contenders[:,0] == net[i])\n",
    "    finalists[i,0] = net[i]\n",
    "    finalists[i,1] = np.sum(contenders[ind,1])\n",
    "\n",
    "finalists = np.unique(finalists, axis = 0)\n",
    "\n",
    "ind = finalists[np.where(finalists[:,1] == max(finalists[:,1]))]\n",
    "\n",
    "ind = int(ind[0,0])\n",
    "\n",
    "print(netflix_simple.iloc[ind]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4548e07b",
   "metadata": {},
   "source": [
    "Finally, we can jam all of this into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "245c7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_rec(title):\n",
    "    \n",
    "    '''A function which takes in the name of a film/TV show as a string and returns a \n",
    "    recommendation using TFIDF.'''\n",
    "    \n",
    "    title = title\n",
    "    \n",
    "    # load in the Netflix library\n",
    "    netflix = pd.read_csv(\"netflix_titles.csv\")\n",
    "    \n",
    "    # take out some of the things we care less about\n",
    "    netflix_simple = netflix.drop(['date_added', 'release_year', 'duration'], axis = 1)\n",
    "\n",
    "    # fill in any NaNs with empty strings so the vectorizing doesn't break\n",
    "    netflix_simple.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # things that don't need extra manipulation\n",
    "    titledesc = netflix_simple['description'] + netflix_simple['title']\n",
    "    \n",
    "    # things that do need some help, since they contain multiword tokens\n",
    "    # what we're doing here is removing all the whitespace so that when we tokenize, there's \n",
    "    # no worry about individual words being tokens instead of full names\n",
    "\n",
    "    for i in range(len(netflix_simple['cast'])):\n",
    "        netflix_simple['cast'].iloc[i] = netflix_simple['cast'].iloc[i].replace(\" \", \"\")\n",
    "        netflix_simple['director'].iloc[i] = netflix_simple['director'].iloc[i].replace(\" \", \"\")\n",
    "        \n",
    "    # like before, assign the colmns to variables so things are cleaner\n",
    "    cast = netflix_simple['cast']\n",
    "    director = netflix_simple['director']\n",
    "    \n",
    "    # Create tfidf vectorizer:\n",
    "    tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
    "\n",
    "    # Use vectorizer to create tfidf matrix.\n",
    "    tfidf_titledesc = tf.fit_transform(titledesc)\n",
    "    tfidf_cast = tf.fit_transform(cast)\n",
    "    tfidf_director = tf.fit_transform(director)\n",
    "    \n",
    "    # Compute the similarity matrix so we know how similar the given movie is to the others available\n",
    "    sim_titledesc = linear_kernel(tfidf_titledesc, tfidf_titledesc)\n",
    "    sim_cast = linear_kernel(tfidf_cast, tfidf_cast)\n",
    "    sim_director = linear_kernel(tfidf_director, tfidf_director)\n",
    "    \n",
    "    # all the things we'll be using for the ranking\n",
    "    metrics = [sim_titledesc, sim_cast, sim_director]\n",
    "    \n",
    "    netflix_simple.reset_index(inplace=True)\n",
    "\n",
    "    # reindex according to title so that the indexing later is easier\n",
    "    indices = pd.Series(netflix_simple.index, index=netflix_simple['title'])\n",
    "    \n",
    "    # this loop will take all the rating categories and combine them into a final \n",
    "    # recommendation list\n",
    "\n",
    "    # this is the title you input at the top of the notebook\n",
    "    # it is used on the reindexed database to pull the information for that entry\n",
    "    index = indices[title]\n",
    "\n",
    "    # an empty array to append to in the loop\n",
    "    contenders = np.zeros((9,2))\n",
    "\n",
    "    for i in metrics:\n",
    "\n",
    "        # for a given category, find the input movie\n",
    "        row = i[index]\n",
    "\n",
    "        # pull the similarity scores for that movie\n",
    "        sim_scores = list(enumerate(row))\n",
    "\n",
    "        # sort the scores, highest score first\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # keep the top 10 entries; entry 0 is excluded because that will almost always\n",
    "        # be the input title\n",
    "        closest_matches = sim_scores[1:11]\n",
    "\n",
    "        # get the numerical indices for the movies\n",
    "        movie_indices = [i[0] for i in closest_matches]\n",
    "\n",
    "        # turn the closest matches into an array\n",
    "        contenders2 = np.array(closest_matches)\n",
    "\n",
    "        # concatenate to the blank array so we can compile the similarity scores later\n",
    "        contenders = np.concatenate((contenders, contenders2))\n",
    "\n",
    "    # exclude the 0 entries from when we made the \"empty\" array earlier;\n",
    "    # keeping them will break the recommendations\n",
    "    contenders = contenders[10:,:]   \n",
    "\n",
    "    # this is just the indices of the movies\n",
    "    net = contenders[:,0]\n",
    "\n",
    "    finalists = np.zeros((len(contenders), 2))\n",
    "\n",
    "    # a loop to skim through the contenders and sum their overall similarity scores\n",
    "    for i in range(len(net)):\n",
    "        ind = np.where(contenders[:,0] == net[i])\n",
    "        finalists[i,0] = net[i]  #index of the movie\n",
    "        finalists[i,1] = np.sum(contenders[ind,1])   #movie's similarity score\n",
    "\n",
    "    finalists = np.unique(finalists, axis = 0)\n",
    "\n",
    "    ind = finalists[np.where(finalists[:,1] == max(finalists[:,1]))]\n",
    "\n",
    "    ind = int(ind[0,0])\n",
    "\n",
    "    rec = netflix_simple.iloc[ind]['title']\n",
    "    \n",
    "    return rec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b576bbac",
   "metadata": {},
   "source": [
    "Some demonstrations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f243751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stuart Little 2\n"
     ]
    }
   ],
   "source": [
    "rec = movie_rec('Stuart Little')\n",
    "print(rec)\n",
    "\n",
    "# Stuart Little 2 is the sequel to Stuart Little, so this is reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60d27b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Love of Spock\n"
     ]
    }
   ],
   "source": [
    "rec = movie_rec('Star Trek')\n",
    "print(rec)\n",
    "\n",
    "# 'For the Love of Spock' is a documentary about Star Trek and Leonard Nimoy, so this is\n",
    "# a reasonable recommendation if you've just finished the JJ Abrams Star Trek reboot movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46b3c05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Trek: Enterprise\n"
     ]
    }
   ],
   "source": [
    "rec = movie_rec('Star Trek: The Next Generation')\n",
    "print(rec)\n",
    "\n",
    "# While Deep Space Nine is probably a better recommendation, getting in the right franchise\n",
    "# is a good sign, and it picked up on which starship to focus on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce84ce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Evil Dead\n"
     ]
    }
   ],
   "source": [
    "rec = movie_rec('Ash vs. Evil Dead')\n",
    "print(rec)\n",
    "\n",
    "# 'Ash vs. Evil Dead' is a spinoff of the 'The Evil Dead' movie franchise, so this is\n",
    "# definitely a good recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b331e",
   "metadata": {},
   "source": [
    "Some difficulties/limitations:\n",
    "\n",
    "* There's a chance that a movie/show won't have a perfect correlation with itself, so it isn't excluded from the recommendation list and may accidentally be recommended to the user.\n",
    "* Sometimes the descriptions in the csv used for this aren't very good, leading to erroneous recommendations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
